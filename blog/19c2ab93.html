<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="bigdata, ai, 中间件、算法、大数据、人工智能"><title>Spark性能调优实战 | Tony's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark性能调优实战</h1><a id="logo" href="/.">Tony's Notes</a><p class="description">Stay Hungry, Stay Foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark性能调优实战</h1><div class="post-meta">Jul 29, 2021<span> | </span><span class="category"><a href="/categories/计算引擎/">计算引擎</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 3.3k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 12</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Spark（Spark SQL）在离线计算场景应用广泛，为了保证Spark应用更好地满足业务场景需求，同时能够在线上稳定地运行，我们需要关注Spark的调优工作。首先，需要了解Spark对外的接口并如何高效地使用；其次要搞清楚内部的运行机制以及参数配置体系；最后是要能够深入分析spark的日志信息。进一步来讲，对于Spark的深度使用者，需要关注社区各个版本的迭代、bug修复以及性能优化的情况，才能更好地打开思路，提高解决问题的效率。</p>
<p>为了方便Spark相关性能问题的排查，本文记录了日常Spark使用过程中遇到的问题和解决思路，用于积累过程中进行复盘总结，强化Spark的深入理解和实战经验。</p>
<a id="more"></a>
<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><ol>
<li><p>针对<code>CET</code>达到几百规模的大SQL在上千规模Hadoop集群的执行性能调优？（仅限SQL层面）</p>
<ul>
<li><code>SparkSQL thriftserver</code>侧的优化：<ul>
<li>元数据读写一些锁的优化，从比较大的锁粒度降到比较小的锁粒度；</li>
<li>引入多线程，提高解析每个互不依赖的子查询的并行度。</li>
</ul>
</li>
<li><code>DAGScheduler</code>侧的优化：<ul>
<li>引入线程池提高Task被调度到Executor的效率，降低调度延迟；</li>
<li>适当调小<code>spark.locality.wait.node</code>，降低延迟调度的时间，提高调度的效率；</li>
<li>适当调大<code>spark.resultGetter.threads</code>的数值，提高处理返回结果的效率。</li>
</ul>
</li>
</ul>
</li>
<li><p>建模分析时，判断一批IP地址是否在原始海量的IP段范围中，性能不理想。抽象为非等值JOIN的优化？</p>
<p>分析物理算子<code>org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec</code>，扩展出一个<code>BroadcastRangeJoinExec</code>算子，通过给那个小表做索引并排序，Join时候就不需要每一条都扫描，只扫描一部分就可以了。</p>
</li>
<li><p>建模分析时，少量重点人员账号与原始数据进行碰撞，性能不理想。在大小表基于非分区字段join时，大表读取的数据过多，执行性能较差？</p>
<p>可以采用<code>Runtime Filter</code>的方式，它的原理和DPP（动态分区裁剪）类似，因为DPP要求你的Join条件中包含了分区字段才会开启DPP，<code>Runtime Filter</code>可以把一些非分区字段条件形成一个filter放到大表上，如果表大表能够过滤较多数据，从而可以提高JOIN的性能。</p>
</li>
<li><p><code>java.lang.OutOfMemoryError: GC overhead limit exceeded</code></p>
<ul>
<li>原因：数据量太大，内存不够。</li>
<li>解决方案：<ul>
<li>增大<code>spark.executor.memory</code>的值，减小<code>spark.executor.cores</code> </li>
<li>减少输入数据量，将原来的数据量分几次任务完成，每次读取其中一部分</li>
</ul>
</li>
</ul>
</li>
<li><p><code>ERROR An error occurred while trying to connect to the Java server (127.0.0.1:57439) Connection refused</code></p>
<ul>
<li>原因：<ul>
<li>节点上运行的container多，每个任务shuffle write到磁盘的量大，导致磁盘满，节点重启 </li>
<li>节点其他服务多，抢占内存资源，NodeManager处于假死状态</li>
</ul>
</li>
<li>解决方案：<ul>
<li>确保节点没有过多其他服务进程 </li>
<li>扩大磁盘容量 </li>
<li>降低内存可分配量，比如为总内存的90%，可分配内存少了，并发任务数就少了，出现问题概率降低 </li>
<li>增大NodeManager的堆内存</li>
</ul>
</li>
</ul>
</li>
<li><p><code>org.apache.spark.shuffle.FetchFailedException: Failed to connect to /9.4.36.40:7337</code></p>
<ul>
<li>背景：shuffle过程包括shuffle read和shuffle write两个过程。对于spark on yarn，shuffle write是container写数据到本地磁盘(路径由core-site.xml中hadoop.tmp.dir指定)过程； shuffle read是container请求external shuffle服务获取数据过程，external shuffle是NodeManager进程中的一个服务，默认端口是7337，或者通过spark.shuffle.service.port指定。</li>
<li>定位过程：拉取任务运行日志，查看container日志；查看对应ip上NodeManager进程运行日志，路径由yarn-env.sh中YARN_LOG_DIR指定。</li>
<li>原因：container请求NodeManager上external shufflle服务，不能正常connect，说明NodeManager可能挂掉了，原因可能是：<ul>
<li>节点上运行的container多，每个任务shuffle write到磁盘的量大，导致磁盘满，节点重启</li>
<li>节点其他服务多，抢占内存资源，NodeManager处于假死状态</li>
</ul>
</li>
<li>解决方案：<ul>
<li>确保节点没有过多其他服务进程 </li>
<li>扩大磁盘容量 </li>
<li>降低内存可分配量，比如为总内存的90%，可分配内存少了，并发任务数就少了，出现问题概率降低</li>
<li>增大NodeManager的堆内存</li>
</ul>
</li>
</ul>
</li>
<li><p><code>org.apache.spark.shuffle.FetchFailedException: Failed to send RPC XXX to /xxx:7337:java.nio.channels.ColsedChannelException</code></p>
<ul>
<li>原因：external shuffle服务将数据发送给container时，发现container已经关闭连接，出现该异常应该和<code>org.apache.spark.shuffle.FetchFailedException: Connection from /xxx:7337 closed</code>同时出现；</li>
<li>解决方案：参考<code>org.apache.spark.shuffle.FetchFailedException: Connection from /xxx:7337 closed</code>的解决方案。</li>
<li>进一步补充：<ul>
<li>在验证中发现关闭参数<code>spark.shuffle.readHostLocalDisk</code>，可以规避该异常的出现；</li>
<li>顺着上述参数发现在<code>spark3.0.0</code>中<code>org.apache.spark.network.shuffle.ExternalBlockStoreClient#getHostLocalDirs</code>指定rpc操作后默认关闭了RPC client，导致后续其他任务使用该client时出现已经关闭的情况。排查发现社区在<a href="https://issues.apache.org/jira/browse/SPARK-32663" target="_blank" rel="noopener">SPARK-32663</a>已经修复了该问题。</li>
</ul>
</li>
</ul>
</li>
<li><p>spark任务中stage有retry</p>
<ul>
<li>原因：<ul>
<li>下一个stage获取上一个stage没有获取到全部输出结果，只获取到部分结果，对于没有获取的输出结果retry stage以产出缺失的结果；</li>
<li>部分输出结果确实已经丢失 ，部分输出结果没有丢失，只是下一个stage获取结果超时，误认为输出结果丢失。</li>
</ul>
</li>
<li>解决方案：<ul>
<li>针对原因(1)，查看进程是否正常，查看机器资源是否正常，比如磁盘是否满或者其他；</li>
<li>针对原因(2)，调大超时时间，如调大<code>spark.network.timeout</code>值。</li>
</ul>
</li>
</ul>
</li>
<li><p><code>Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (200) reached)</code></p>
<ul>
<li>原因：executor失败重试次数达到阈值</li>
<li>解决方案：<ul>
<li>调整运行参数，减少executor失败次数；</li>
<li>调整<code>spark.yarn.max.executor.failures</code>的值，可在spark-defaults.conf中调整。确定方式，在日志中搜索”Final app status:”，确定原因，在日志统计”Container marked as failed:”出现次数。</li>
</ul>
</li>
</ul>
</li>
<li><p>task反复调度到有问题的executor？</p>
<p>通过这些黑名单的设置可以避免由于 task 反复调度在有问题的 <code>executor/node</code> （坏盘，磁盘满了，shuffle fetch 失败，环境错误等）上，进而导致整个 <code>Application</code> 运行失败的情况。</p>
</li>
</ol>
<h2 id="Shuffle参数"><a href="#Shuffle参数" class="headerlink" title="Shuffle参数"></a>Shuffle参数</h2><table>
<thead>
<tr>
<th>配置</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>spark.shuffle.readHostLocalDisk</code></td>
<td>true</td>
<td>当<code>spark.shuffle.useOldFetchProtocol</code>关闭，<code>spark.shuffle.service.enabled</code>开启。从运行在同一个主机上block manager获取block shuffle可以直接读取本地磁盘而不是走remote方式远程拉取。</td>
</tr>
<tr>
<td><code>spark.shuffle.io.backLog</code></td>
<td>8192</td>
<td>shuffle 服务的接收队列的长度。默认128</td>
</tr>
<tr>
<td><code>spark.shuffle.io.serverThreads</code></td>
<td>6</td>
<td>shuffle 服务线程数</td>
</tr>
<tr>
<td><code>spark.shuffle.io.connectionTimeout</code></td>
<td>120s</td>
<td>shuffle client连接超时时间</td>
</tr>
<tr>
<td><code>spark.network.timeout</code></td>
<td>300s</td>
<td></td>
</tr>
<tr>
<td><code>spark.shuffle.service.index.cache.size</code></td>
<td>2048m</td>
<td>shuffle文件的索引大小</td>
</tr>
<tr>
<td><code>spark.dynamicAllocation.executorIdleTimeout</code></td>
<td>1800s</td>
<td></td>
</tr>
<tr>
<td><code>spark.reducer.maxSizeInFlight</code></td>
<td>48m</td>
<td>从每个reduce任务同时抓取map输出数据的最大大小，由于每个输出数据需要创建一个缓冲区来接受，是每个reduce任务固定的内存开销，因此需要设置一个较小的值，除非有大量的内存</td>
</tr>
<tr>
<td><code>spark.reducer.maxReqsInFlight</code></td>
<td>Int.MaxValue</td>
<td>限制了每个主机每次进行reduce操作时可以被多少台远程主机拉取文件块，配置在任何给定节点获取块的请求远程请求数，当集群中主机数量增加时，可能会导致一个或者多个节点的入站连接数量非常多，导致负载失败，限制次参数，可以缓解这种情况</td>
</tr>
<tr>
<td><code>spark.shuffle.compress</code></td>
<td>true</td>
<td>是否压缩map输出文件，默认压缩 true，spark2.2之前默认压缩方式snappy，spark2.2之后默认是lz4</td>
</tr>
<tr>
<td><code>spark.shuffle.file.buffer</code></td>
<td>32k</td>
<td>在内存输出流中 每个shuffle文件占用内存大小，适当提高 可以减少磁盘读写 io次数，初始值为32k</td>
</tr>
<tr>
<td><code>spark.shuffle.io.maxRetries</code></td>
<td>3</td>
<td>shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。 对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。</td>
</tr>
<tr>
<td><code>spark.shuffle.io.numConnectionsPerPeer</code></td>
<td>1</td>
<td>机器之间的可以重用的网络连接，主要用于在大型集群中减小网络连接的建立开销，如果一个集群的机器并不多，可以考虑增加这个值</td>
</tr>
<tr>
<td><code>spark.shuffle.io.preferDirectBufs</code></td>
<td>true</td>
<td>启用堆外内存，可以避免shuffle过程的频繁gc，如果堆外内存非常紧张，则可以考虑关闭这个选项</td>
</tr>
<tr>
<td><code>spark.shuffle.io.retryWait</code></td>
<td>5s</td>
<td>每次重试拉取数据的等待间隔，默认是5s，建议加大时长，理由同上，保证shuffle操作的稳定性</td>
</tr>
<tr>
<td><code>spark.shuffle.service.enabled</code></td>
<td>false</td>
<td>启用外部shuffle服务，这个服务会安全地保存shuffle过程中，executor写的磁盘文件，因此executor即使挂掉也不要紧，必须配合<code>spark.dynamicAllocation.enabled</code>属性设置为true，才能生效，而且外部shuffle服务必须进行安装和启动，才能启用这个属性</td>
</tr>
<tr>
<td><code>spark.shuffle.service.port</code></td>
<td>7337</td>
<td>外部shuffle服务的端口号，具体解释同上</td>
</tr>
<tr>
<td><code>spark.shuffle.service.index.cache.entries</code></td>
<td>1024</td>
<td>在shuffle服务的索引缓存中最大条目数</td>
</tr>
<tr>
<td><code>spark.shuffle.sort.bypassMergeThreshold</code></td>
<td>200</td>
<td>对于sort-based ShuffleManager，如果没有进行map side聚合，而且reduce task数量少于这个值，那么就不会进行排序，如果你使用sort ShuffleManager，而且不需要排序，那么可以考虑将这个值加大，直到比你指定的所有task数量都大，以避免进行额外的sort，从而提升性能</td>
</tr>
<tr>
<td><code>spark.shuffle.spill.compress</code></td>
<td>true</td>
<td>shuffle过程中溢出的文件是否压缩，默认true，使用<code>spark.io.compression.codec</code>压缩。spark2.2之前默认压缩方式snappy，spark2.2之后默认是lz4</td>
</tr>
<tr>
<td><code>spark.shuffle.accurateBlockThreshold</code></td>
<td>100 <em> 1024 </em> 1024</td>
<td>以字节为单位的阈值，高于该阈值可准确记录HighlyCompressedMapStatus中随机块的大小。这有助于通过避免在获取shuffle块时低估shuffle块大小来防止OOM。</td>
</tr>
<tr>
<td><code>spark.io.encryption.enabled</code></td>
<td>false</td>
<td>是否启用加密，目前支持除mesos外的所有模式，建议使用前先开启RPC加密</td>
</tr>
<tr>
<td><code>spark.io.encryption.keySizeBits</code></td>
<td>128</td>
<td>IO加密密钥大小，单位是位</td>
</tr>
<tr>
<td><code>spark.io.encryption.keygen.algorithm</code></td>
<td>HmacSHA1</td>
<td>生成IO加密密钥时使用的算法</td>
</tr>
</tbody>
</table>
<h3 id="BlackList参数"><a href="#BlackList参数" class="headerlink" title="BlackList参数"></a>BlackList参数</h3><table>
<thead>
<tr>
<th>配置</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>spark.blacklist.enabled</code></td>
<td>false</td>
<td>是否开启黑名单机制</td>
</tr>
<tr>
<td><code>spark.blacklist.timeout</code></td>
<td>1h</td>
<td>对于被加入 application 黑名单的 executor/节点 ，多长时间后无条件的移出黑名单以运行新任务</td>
</tr>
<tr>
<td><code>spark.blacklist.task.maxTaskAttemptsPerExecutor</code></td>
<td>1</td>
<td>对于同一个 task 在某个 executor 中的失败重试阈值。达到阈值后，在执行这个 task 时，该 executor 将被加入黑名单</td>
</tr>
<tr>
<td><code>spark.blacklist.task.maxTaskAttemptsPerNode</code></td>
<td>2</td>
<td>对于同一个 task 在某个节点上的失败重试阈值。达到阈值后，在执行这个 task 时，该节点将被加入黑名单</td>
</tr>
<tr>
<td><code>spark.blacklist.stage.maxFailedTasksPerExecutor</code></td>
<td>2</td>
<td>一个 stage 中，不同的 task 在同一个 executor 的失败阈值。达到阈值后，在执行这个 stage 时该 executor 将会被加入黑名单</td>
</tr>
<tr>
<td><code>spark.blacklist.stage.maxFailedExecutorsPerNode</code></td>
<td>2</td>
<td>一个 stage 中，不同的 executor 加入黑名单的阈值。达到阈值后，在执行这个 stage 时该节点将会被加入黑名单</td>
</tr>
<tr>
<td><code>spark.blacklist.application.maxFailedTasksPerExecutor</code></td>
<td>2</td>
<td>在同一个 executor 中，不同的 task的失败阈值 。达到阈值后，在整个 appliction 运行期间，该 executor 都会被加入黑名单，加入时间超过 <code>spark.blacklist.timeout</code> 后，自动从黑名单中移除。值得注意的是，如果开启了 <code>dynamic allocation</code>，这些 executor 可能会由于空闲时间过长被回收。</td>
</tr>
<tr>
<td><code>spark.blacklist.application.maxFailedExecutorsPerNode</code></td>
<td>2</td>
<td>在一个节点中，不同 executor 加入 application 黑名单的阈值。达到这个阈值后，该节点会进入 application 黑名单，加入时间超过 <code>spark.blacklist.timeout</code> 后，自动从黑名单中移除。值得注意的是，如果开启了 <code>dynamic allocation</code>，该节点上的 executor 可能会由于空闲时间过长被回收。</td>
</tr>
<tr>
<td><code>spark.blacklist.killBlacklistedExecutors</code></td>
<td>false</td>
<td>如果开启该配置，spark 会自动关闭并重启加入黑名单的 executor，如果整个节点都加入了黑名单，则该节点上的所有 executor 都会被关闭。</td>
</tr>
<tr>
<td><code>spark.blacklist.application.fetchFailure.enabled</code></td>
<td>false</td>
<td>如果开启该配置，当发生 <code>fetch failure</code>时，立即将该 executor 加入到黑名单。要是开启了 <code>external shuffle service</code>，整个节点都会被加入黑名单。</td>
</tr>
</tbody>
</table>
<h3 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/_KWwb80dlkEtu1SeRK4jqw" target="_blank" rel="noopener">Apache Spark 完全替代传统数仓的技术挑战及实践</a>，马刚@eBay，大数据团队成员</li>
</ul>
</div><iframe src="/donate/?AliPayQR=/uploads/alipay.png&amp;WeChatQR=null&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://changbo.tech/blog/19c2ab93.html" data-id="cksddowhn001liwvx6u74hjf6" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAAByElEQVR42u3aQY6DMBAEwPz/0+w10gbT48FWiMqnCAKUObTsGV6veBxv4/3I+Gx+/OaBi4vb5h7D8R83viqfQHL2w5RwcXE3cs8SY/z7DDeeWHLP0+O4uLgP4VZxuLi4v8RNJpBAcXFxn8Ktbmbmprd1r4aLi9vg5lXKdb+X1HdxcXGnuEdxjAOreofytbi4uFu4c62Us8VHskCpHv8Qebi4uFu4SWFiXO5MFkZJUTUpreLi4q7mdtqlc1umpKFysSLDxcVdzE2ipx9w1SjExcX9Bu44SsYPrv4nv/ai84OLi7uMm0CT/KteWy6C4OLibuTmpYpqD/Sul1L4ZgQXF/cmbt4U6W+HqpO56Png4uIu4yafXvVLotWlVSF3cXFxl3GrG558MZQUQaoLKVxc3D3c6gPy0JlrlhS2Ybi4uMu4c+2TPOaqE4saKri4uBu5ndZp9Q5JmBZWZLi4uDdxj+KY63XmgXVxZ1xc3C3cdQ3UJEGr2yRcXNyd3P52JS+jdOobuLi4+7mdBmoeWP3oxMXF/U5uFT1XHsXFxX0it18Snfv8CxcXdye3+klEP7aq6YSLi7uTW42SvMkxRicvolXfxcXFneH+ASHXAS8FWtx9AAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a class="pre" href="/blog/ce4ffa9b.html">Hive性能调优实践</a><a class="next" href="/blog/c50a937d.html">PMP实践之路</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人日志/">个人日志</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/云原生/">云原生</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式/">分布式</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/存储引擎/">存储引擎</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库与大数据/">数据库与大数据</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器/">服务器</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算引擎/">计算引擎</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/">读书笔记</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维工具/">运维工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目管理/">项目管理</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/OLAP/" style="font-size: 15px;">OLAP</a> <a href="/tags/B-树/" style="font-size: 15px;">B+树</a> <a href="/tags/职场感悟/" style="font-size: 15px;">职场感悟</a> <a href="/tags/技术管理/" style="font-size: 15px;">技术管理</a> <a href="/tags/开源协议/" style="font-size: 15px;">开源协议</a> <a href="/tags/Drill/" style="font-size: 15px;">Drill</a> <a href="/tags/查询计划/" style="font-size: 15px;">查询计划</a> <a href="/tags/SQL引擎/" style="font-size: 15px;">SQL引擎</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/MPP/" style="font-size: 15px;">MPP</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/NoSQL/" style="font-size: 15px;">NoSQL</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/类加载器/" style="font-size: 15px;">类加载器</a> <a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/正向代理/" style="font-size: 15px;">正向代理</a> <a href="/tags/反向代理/" style="font-size: 15px;">反向代理</a> <a href="/tags/InnoDB/" style="font-size: 15px;">InnoDB</a> <a href="/tags/RocksDB/" style="font-size: 15px;">RocksDB</a> <a href="/tags/LSM树/" style="font-size: 15px;">LSM树</a> <a href="/tags/存储引擎/" style="font-size: 15px;">存储引擎</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/GC/" style="font-size: 15px;">GC</a> <a href="/tags/Kylin/" style="font-size: 15px;">Kylin</a> <a href="/tags/业务/" style="font-size: 15px;">业务</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/SQL/" style="font-size: 15px;">SQL</a> <a href="/tags/helm/" style="font-size: 15px;">helm</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/Calcite/" style="font-size: 15px;">Calcite</a> <a href="/tags/优化器/" style="font-size: 15px;">优化器</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/CBO/" style="font-size: 15px;">CBO</a> <a href="/tags/算法复杂度/" style="font-size: 15px;">算法复杂度</a> <a href="/tags/数据库/" style="font-size: 15px;">数据库</a> <a href="/tags/分布式事务/" style="font-size: 15px;">分布式事务</a> <a href="/tags/ACID/" style="font-size: 15px;">ACID</a> <a href="/tags/CAP/" style="font-size: 15px;">CAP</a> <a href="/tags/Raft/" style="font-size: 15px;">Raft</a> <a href="/tags/分布式一致性/" style="font-size: 15px;">分布式一致性</a> <a href="/tags/AnalyticDB/" style="font-size: 15px;">AnalyticDB</a> <a href="/tags/行列存储/" style="font-size: 15px;">行列存储</a> <a href="/tags/Catalyst/" style="font-size: 15px;">Catalyst</a> <a href="/tags/Intel/" style="font-size: 15px;">Intel</a> <a href="/tags/ARM/" style="font-size: 15px;">ARM</a> <a href="/tags/X86/" style="font-size: 15px;">X86</a> <a href="/tags/硬件/" style="font-size: 15px;">硬件</a> <a href="/tags/RAID/" style="font-size: 15px;">RAID</a> <a href="/tags/服务器/" style="font-size: 15px;">服务器</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/并发编程/" style="font-size: 15px;">并发编程</a> <a href="/tags/窗口函数/" style="font-size: 15px;">窗口函数</a> <a href="/tags/大数据meetup/" style="font-size: 15px;">大数据meetup</a> <a href="/tags/博客/" style="font-size: 15px;">博客</a> <a href="/tags/IT资讯/" style="font-size: 15px;">IT资讯</a> <a href="/tags/故障诊断/" style="font-size: 15px;">故障诊断</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/书籍/" style="font-size: 15px;">书籍</a> <a href="/tags/论文/" style="font-size: 15px;">论文</a> <a href="/tags/TopK/" style="font-size: 15px;">TopK</a> <a href="/tags/数据结构/" style="font-size: 15px;">数据结构</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/6d27f500.html">Java类加载机制</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/b9b847a8.html">SparkSQL业务分析集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/bfe7107d.html">OLAP引擎-Kylin基本介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/ce4ffa9b.html">Hive性能调优实践</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/19c2ab93.html">Spark性能调优实战</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/c50a937d.html">PMP实践之路</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/7dec2e4.html">Calcite处理和扩展流程解析</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/4c70dee6.html">分布式事务与一致性</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/75c48487.html">2020-DTCC-参会分享</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/8fd5028b.html">SparkSQL窗口函数实操</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://changbo.tech/blog/ec4cdf4c.html" title="行业博客" target="_blank">行业博客</a><ul></ul><a href="https://leetcode-cn.com/" title="leetcode" target="_blank">leetcode</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">Tony's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>