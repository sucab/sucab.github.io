<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="bigdata, ai, 中间件、算法、大数据、人工智能"><title>Hive性能调优实践 | Tony's Notes</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hive性能调优实践</h1><a id="logo" href="/.">Tony's Notes</a><p class="description">Stay Hungry, Stay Foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hive性能调优实践</h1><div class="post-meta">Aug 5, 2021<span> | </span><span class="category"><a href="/categories/计算引擎/">计算引擎</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 4.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 16</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><h2 id="Hive基本介绍"><a href="#Hive基本介绍" class="headerlink" title="Hive基本介绍"></a>Hive基本介绍</h2><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/blog/ce4ffa9b/hive_archi.png" alt></p>
<p>Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<ul>
<li><p>用户接口：Client</p>
<p>CLI（hive shell）、JDBC/ODBC(java访问hive)、WEBUI（浏览器访问hive）</p>
</li>
<li><p>元数据：Metastore</p>
<p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；默认存储在自带的derby数据库中，也可以使用MySQL/PG存储Metastore。</p>
</li>
<li><p>Hadoop</p>
<p>使用HDFS进行存储，使用MapReduce进行计算。</p>
</li>
<li><p>驱动器：Driver</p>
<ul>
<li>解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</li>
<li>编译器（Physical Plan）：将AST编译生成逻辑执行计划。</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化。</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</li>
</ul>
</li>
</ul>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li><p>操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。</p>
</li>
<li><p>避免了去写MapReduce，减少开发人员的学习成本。</p>
</li>
<li><p>Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。</p>
</li>
<li><p>Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。</p>
</li>
<li><p>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p>
</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li><p>Hive的HQL表达能力有限</p>
<ul>
<li><p>迭代式算法无法表达</p>
</li>
<li><p>数据挖掘方面不擅长</p>
</li>
</ul>
</li>
<li><p>Hive的效率比较低</p>
<ul>
<li>Hive自动生成的MapReduce作业，通常情况下不够智能化</li>
<li>Hive调优比较困难，粒度较粗</li>
</ul>
</li>
</ul>
<h2 id="Hive核心概念"><a href="#Hive核心概念" class="headerlink" title="Hive核心概念"></a>Hive核心概念</h2><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><ul>
<li>Order By：全局排序，一个Reducer，ASC（ascend）升序（默认），DESC（descend） 降序；</li>
<li>Sort By：每个Reducer内部进行排序，对全局结果集来说不是排序。<code>set mapreduce.job.reduces=3;</code>；</li>
<li>Distribute By：类似MR中partition进行分区，结合sort by使用。注意，Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前；</li>
<li>Cluster By：当distribute by和sorts by字段相同时，可以使用cluster by方式。cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</li>
</ul>
<h3 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h3><table>
<thead>
<tr>
<th>Hive数据类型</th>
<th>Java数据类型</th>
<th>长度</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td>TINYINT</td>
<td>byte</td>
<td>1byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
<td>2byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
<td>4byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
<td>8byte有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
<td>布尔类型，true或者false</td>
<td>TRUE  FALSE</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
<td>单精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
<td>双精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>STRING</td>
<td>string</td>
<td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td>
<td>‘now is the time’ “for all good men”</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td></td>
<td>时间类型</td>
<td></td>
</tr>
<tr>
<td>BINARY</td>
<td></td>
<td>字节数组</td>
</tr>
</tbody>
</table>
<h3 id="复合类型"><a href="#复合类型" class="headerlink" title="复合类型"></a>复合类型</h3><table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
<th>语法示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRUCT</td>
<td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td>
<td>struct()</td>
</tr>
<tr>
<td>MAP</td>
<td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td>
<td>map()</td>
</tr>
<tr>
<td>ARRAY</td>
<td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td>
<td>Array()</td>
</tr>
</tbody>
</table>
<h2 id="调优实践"><a href="#调优实践" class="headerlink" title="调优实践"></a>调优实践</h2><h3 id="Fetch抓取"><a href="#Fetch抓取" class="headerlink" title="Fetch抓取"></a>Fetch抓取</h3><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
<h3 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h3><p>用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<h3 id="MapJoin"><a href="#MapJoin" class="headerlink" title="MapJoin"></a>MapJoin</h3><p>如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 设置自动选择Mapjoin</span></span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join = <span class="literal">true</span>; 默认为true</span><br><span class="line"><span class="comment">-- 大表小表的阈值设置（默认25M一下认为是小表）：</span></span><br><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize=<span class="number">25000000</span>;</span><br></pre></td></tr></table></figure>
<h3 id="Group-By"><a href="#Group-By" class="headerlink" title="Group By"></a>Group By</h3><p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 是否在Map端进行聚合，默认为True</span></span><br><span class="line"><span class="keyword">set</span> hive.map.aggr = <span class="literal">true</span></span><br><span class="line"><span class="comment">-- 在Map端进行聚合操作的条目数目</span></span><br><span class="line"><span class="keyword">set</span> hive.groupby.mapaggr.checkinterval = <span class="number">100000</span></span><br><span class="line"><span class="comment">-- 有数据倾斜的时候进行负载均衡（默认是false）</span></span><br><span class="line"><span class="keyword">set</span> hive.groupby.skewindata = <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="Count-Distinct-去重统计"><a href="#Count-Distinct-去重统计" class="headerlink" title="Count(Distinct) 去重统计"></a>Count(Distinct) 去重统计</h3><p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换。</p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><ul>
<li><p>合理设置Map数</p>
<ul>
<li>决定map数量的因素有哪些？</li>
</ul>
<p>主要的决定因素有：<strong>input的文件总个数，input的文件大小，集群设置的文件块大小</strong>。</p>
<ul>
<li>是不是map数越多越好？<br><strong>如果一个任务有很多小文件（远远小于块大小128m）</strong>，则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。<br><strong>比如有一个127m的文件</strong>，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</li>
</ul>
</li>
<li><p>小文件合并</p>
<p>在map执行前合并小文件，减少map数：<code>CombineHiveInputFormat</code>具有对小文件进行合并的功能（系统默认的格式），<code>HiveInputFormat</code>没有对小文件合并功能。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.input.format = org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>
</li>
<li><p>调整Map数</p>
<p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调整maxSize最大值</span></span><br><span class="line"><span class="comment">// 让maxSize最大值低于blocksize就可以增加map的个数</span></span><br><span class="line">computeSliteSize(Math.max(minSize, Math.min(maxSize, blocksize))) = blocksize = <span class="number">128</span>M</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 设置最大切片值为100个字节</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.input.fileinputformat.split.maxsize=<span class="number">100</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>调整Reduce数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 方法一</span></span><br><span class="line"><span class="comment">-- 每个Reduce处理的数据量默认是256MB</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=<span class="number">256000000</span></span><br><span class="line"><span class="comment">-- 每个任务最大的reduce数，默认为1009</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.reducers.max=<span class="number">1009</span></span><br><span class="line"><span class="comment">-- 计算reducer数的公式</span></span><br><span class="line">N=<span class="keyword">min</span>(参数<span class="number">2</span>，总输入数据量/参数<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 方法二</span></span><br><span class="line"><span class="comment">-- 在hadoop的mapred-default.xml文件中修改</span></span><br><span class="line"><span class="comment">-- 设置每个job的Reduce个数</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces = <span class="number">15</span>;</span><br></pre></td></tr></table></figure>
<p>过多的启动和初始化reduce也会消耗时间和资源。另外，<strong>有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题</strong>。</p>
</li>
</ul>
<h3 id="并行执行"><a href="#并行执行" class="headerlink" title="并行执行"></a>并行执行</h3><p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 打开任务并行执行</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 同一个sql允许最大并行度，默认为8</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number=<span class="number">16</span>;</span><br></pre></td></tr></table></figure>
<h3 id="JVM重用"><a href="#JVM重用" class="headerlink" title="JVM重用"></a>JVM重用</h3><p>JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>How many tasks to run per jvm. If set to -1, there is</span><br><span class="line">  no limit. </span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h3 id="推测执行"><a href="#推测执行" class="headerlink" title="推测执行"></a>推测执行</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mapred-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks </span><br><span class="line">               may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- hive配置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.reduce.tasks.speculative.execution<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether speculative execution for reducers should be turned on. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="扩展内容"><a href="#扩展内容" class="headerlink" title="扩展内容"></a>扩展内容</h2><h3 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h3><ul>
<li>union调优</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> xx</span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">from</span> a</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">from</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> a</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> xx <span class="keyword">select</span> ...</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> xx <span class="keyword">select</span> ...</span><br></pre></td></tr></table></figure>
<ul>
<li>数据块大小</li>
</ul>
<p>一个文件由2个数据块构成，在hdfs namenode不紧张的情况，多个不同节点上的map读取这个数据块，本地性较差，需要走网络拉取数据。相比于，一个文件由10个数据块构成，多个不同节点上map本地性较好，减少了网络传输，性能会有所提升。</p>
<ul>
<li>数据格式</li>
</ul>
<p>ORC对hive数据存储主流之一</p>
<ul>
<li>表设计</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- hive分区表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> xx (...)</span><br><span class="line">partitioned <span class="keyword">by</span> (f1 <span class="built_in">bigint</span>)</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> orc;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line"></span><br><span class="line"><span class="comment">--hive分桶表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> yy(..., f2 <span class="built_in">int</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (f2) <span class="keyword">into</span> n buckets</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> orc;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--hive分区分桶表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> yy(..., f2 <span class="built_in">int</span>)</span><br><span class="line">partitioned <span class="keyword">by</span>(f1 <span class="built_in">bigint</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (f2) <span class="keyword">into</span> n buckets</span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> orc;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>
<p>表的设计对于HiveSQL的性能有一定的影响，并不能说明分区分桶表性能一定比只分桶的表性能差，因为基于不同业务和上层的计算逻辑，表现出来的性能差异也会不同。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Hive构建在大数据集群之上，包括了<strong>分布式计算</strong>、<strong>分布式存储</strong>和<strong>分布式调度</strong>等多个系统。因此，Hive的调优并不是单方面的调优，是一个涉及多个组件的系统化工程。</p>
<h2 id="调优思路"><a href="#调优思路" class="headerlink" title="调优思路"></a>调优思路</h2><h3 id="分布式计算"><a href="#分布式计算" class="headerlink" title="分布式计算"></a>分布式计算</h3><p>学习大数据分布式计算的基本原理，比如MapReduce、Spark等。</p>
<h3 id="分布式调度"><a href="#分布式调度" class="headerlink" title="分布式调度"></a>分布式调度</h3><p>学习使用YARN提供的日志，查看Job运行量化信息。</p>
<h3 id="调优三部曲"><a href="#调优三部曲" class="headerlink" title="调优三部曲"></a>调优三部曲</h3><h4 id="改写SQL"><a href="#改写SQL" class="headerlink" title="改写SQL"></a>改写SQL</h4><p>grouping sets代替union、分解count(distinct)为count(group by)</p>
<p>比如，在小数据量下count(distinct)会优于count(group by)，但大数据量数据发生倾斜时，count(group by)优于count(distinct)，因为count(group by)会分为两个作业，第一阶段先处理一部分数据，缩小数据量。第二阶段在缩小的数据量上继续处理。在hive3.0中，开启hive.optimize.countdistinct，会自动调优count(disctinct)。</p>
<p>调优讲究适时调优，过早进行调优有可能做无用功，因此调优需要遵循一定的原则。如下：</p>
<ul>
<li><p>理透需求原则，这是优化根本；</p>
</li>
<li><p>把握数据全链路原则，这是优化脉络；</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看元数据</span></span><br><span class="line">desc formatted table;</span><br><span class="line"><span class="comment">-- 查看表字段、所属数据、创建时间、hdfs路径、文件个数、数据量、serdes、input/outputformat、是否压缩、分桶等</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 运行环境</span></span><br><span class="line"><span class="comment">-- 资源管理：yarn、任务调度：oozie、airflow坚持代码的简洁原则，这让优化更加简单；</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>没有瓶颈时谈论优化，这是自寻烦恼。</p>
<ul>
<li>第一类问题：影响项目整体落地的问题、重大性能问题，在项目设计阶段就要规避。</li>
<li>第二类问题：不影响项目整体落地，但是影响部分功能，根据具体的业务要求进行调优，将优化放到有瓶颈点的地方去考虑和讨论。</li>
</ul>
</li>
</ul>
<h4 id="SQL-hint使用"><a href="#SQL-hint使用" class="headerlink" title="SQL-hint使用"></a>SQL-hint使用</h4><p>mapjoin、streamtable等hint使用</p>
<h4 id="数据库配置调整"><a href="#数据库配置调整" class="headerlink" title="数据库配置调整"></a>数据库配置调整</h4><p>hive.vectorized.execution.enabled开启向量化、hive.exec.parallel、hive.exec.paralledl.thread.number</p>
<h3 id="Hive规范"><a href="#Hive规范" class="headerlink" title="Hive规范"></a>Hive规范</h3><h4 id="开发规范"><a href="#开发规范" class="headerlink" title="开发规范"></a>开发规范</h4><ul>
<li>单条SQL长度不宜超过一屏。</li>
<li>SQL子查询嵌套不宜超过3层。</li>
<li>少用或者不用Hint，特别是在Hive2.0之后，增强HiveSQL对于成本优化(CBO)的支持，在业务环境变化时可能会导致Hive无法选用最优的执行计划。</li>
<li>避免SQL代码的复制、粘贴。如果有多处逻辑一致的代码，可以将执行结果存储在临时表中。</li>
<li>尽可能使用SQL自带党的高级命令做操作。比如多维统计中使用cube、grouping set和roll up等命令去替代多个SQL子句的union all。</li>
<li>使用set命令，进行配置属性的更改，要有注释。</li>
<li>代码里面不允许包含对表、分区、列的DDL语句，除了新增或删除分区。</li>
<li>Hive SQL更加适合处理多条数据组合的数据集，不适合处理单条数据，且单条数据之间存在顺序依赖等逻辑关系。</li>
<li>保持一个查询语句所处理的表类型单一。比如，一个SQL语句中的表都是ORC或Parquet。</li>
<li>关注NULL值得数据处理。</li>
<li>SQL表连接的条件列和查询的过滤列最好要有分区列和分桶列。</li>
<li>存在多层嵌套，内层嵌套表的过滤条件不要写到外层。</li>
</ul>
<h4 id="设计规范"><a href="#设计规范" class="headerlink" title="设计规范"></a>设计规范</h4><ul>
<li>表结构要有注释。</li>
<li>列等属性字段要有注释。</li>
<li>尽量不要使用索引。hive中处理批量处理大量数据，hive索引在表和分区有数据更新时不会自动维护，需要手动触发。索引在hive3.0之后被废弃，使用物化视图或数据存储采用ORC格式可以替代索引的功能。</li>
<li>创建内部表不允许指定数据存储路劲，由管理人员统一规划目录并固化在配置中。</li>
<li>创建非接口表，只允许使用ORC或Parquet。接口表指与其他系统进行的数据表，比如导入hive的临时表或者提供给其他系统使用的输出表。</li>
<li>HIVE适合处理宽边（列数多的表），适当的冗余有助于Hive的处理性能。</li>
<li>表的文件块大小要与HDFS的数据块大小大致相等。</li>
<li>分区表和分桶表的适用。</li>
</ul>
<h4 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h4><ul>
<li>表以tb_开头；</li>
<li>临时表以tmp_开头；</li>
<li>视图以v_开头；</li>
<li>自定义函数以udf_开头；</li>
<li>原始数据所在的库以db_org_ 开头，明细数据所在库以db_detail_ 开头，数据仓库以db_dw_ 开头。</li>
</ul>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>优化基本流程：</p>
<ul>
<li>选择性能评估以及各自目标，时延和吞吐量</li>
<li>系统由多个组件和服务构成，分组件和服务定义性能目标</li>
<li>明确当前环境下各个组件的性能</li>
<li>分析定位性能瓶颈：hive常见是磁盘和网络IO的瓶颈，其次是内存。涉及hive的执行计划、计算引擎基本原理。</li>
<li>优化产生性能瓶颈的程序或者系统：优化存储、执行过程和作业调度。</li>
<li>性能监控和告警：<ul>
<li>在操作系统和硬件层面借助linux系统提供的工具，或者zabbix和ganglia开源工具。</li>
<li>软件层面，借助prometheus和grafana定制监控大数据组件。</li>
<li>作业层面，借助yarn timeline提供查看作业信息的监控。</li>
</ul>
</li>
</ul>
<h3 id="扩展阅读"><a href="#扩展阅读" class="headerlink" title="扩展阅读"></a>扩展阅读</h3><ul>
<li><a href="https://mp.weixin.qq.com/s/ORYKS1gS0S8PHgKROhmXmw" target="_blank" rel="noopener">Hive知识体系保姆级教程-超全概括</a></li>
</ul>
</div><iframe src="/donate/?AliPayQR=/uploads/alipay.png&amp;WeChatQR=null&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="http://changbo.tech/blog/ce4ffa9b.html" data-id="cksluobq7001dvkvxw8ykoy1r" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABzUlEQVR42u3ay23EMAwFQPff9KaAQPYjuVIcYHQKAq089oHgR9cVr89i3e9Mzrx2LFxc3DH3c7tWe+7//xtUPX/52ri4uAe594FmRamGttWZiQEXF/fN3PsHJwlNfgIuLu5/4eZJz+R8XFzcN3CT4qTa5vjjWg0XF3fAzbuU+/7e0t/FxcVtcT/FVR2x9MLW8kxcXNwj3Gr6MkliktFL9FxcXNzN3GrZkzcyJtnWQwjDxcXdzJ2DkgRoHgqXcRcXF3cztxe87pOYXmh7aNfi4uIe4eab8rQm+QTVYgkXF/dvuXn7stdsvQ9q0bgFFxd3G7fa2shLl8l1ruWZuLi4R7i9dCSH9gLcF2o1XFzcbdzqOKTXXslTKFxc3JPc3mXNauozvyqKi4t7klsdhVbfPkpcevfIcHFxN3OTgqeKyKGF9gouLu5xbjWh6V3qGmVhuLi4m7m9wWo+JqkOaK9qroSLi7uBO2+G5oVTr3XSfBlcXNwxNw86+f7k2zQvb+Hi4h7k9oYo1SFrtfh56O/i4uK+jHv/4OS31XILFxf3zdzeVcvJdatRIMPFxR1wq83NvJFRHcE+fCBcXNwj3HIoabVBq02WL/R3cXFxO9wfkH25aLFBy3QAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/Hive/">Hive</a></div><div class="post-nav"><a class="pre" href="/blog/bfe7107d.html">OLAP引擎-Kylin基本介绍</a><a class="next" href="/blog/19c2ab93.html">Spark性能调优实战</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人日志/">个人日志</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/云原生/">云原生</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式/">分布式</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/存储引擎/">存储引擎</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库与大数据/">数据库与大数据</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器/">服务器</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算引擎/">计算引擎</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/论文阅读/">论文阅读</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/">读书笔记</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维工具/">运维工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目管理/">项目管理</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/OLAP/" style="font-size: 15px;">OLAP</a> <a href="/tags/SQL引擎/" style="font-size: 15px;">SQL引擎</a> <a href="/tags/B-树/" style="font-size: 15px;">B+树</a> <a href="/tags/职场感悟/" style="font-size: 15px;">职场感悟</a> <a href="/tags/技术管理/" style="font-size: 15px;">技术管理</a> <a href="/tags/开源协议/" style="font-size: 15px;">开源协议</a> <a href="/tags/Drill/" style="font-size: 15px;">Drill</a> <a href="/tags/查询计划/" style="font-size: 15px;">查询计划</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/NoSQL/" style="font-size: 15px;">NoSQL</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/MPP/" style="font-size: 15px;">MPP</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/GC/" style="font-size: 15px;">GC</a> <a href="/tags/InnoDB/" style="font-size: 15px;">InnoDB</a> <a href="/tags/RocksDB/" style="font-size: 15px;">RocksDB</a> <a href="/tags/LSM树/" style="font-size: 15px;">LSM树</a> <a href="/tags/存储引擎/" style="font-size: 15px;">存储引擎</a> <a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/正向代理/" style="font-size: 15px;">正向代理</a> <a href="/tags/反向代理/" style="font-size: 15px;">反向代理</a> <a href="/tags/Kylin/" style="font-size: 15px;">Kylin</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/类加载器/" style="font-size: 15px;">类加载器</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/SQL/" style="font-size: 15px;">SQL</a> <a href="/tags/业务/" style="font-size: 15px;">业务</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/helm/" style="font-size: 15px;">helm</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/Calcite/" style="font-size: 15px;">Calcite</a> <a href="/tags/优化器/" style="font-size: 15px;">优化器</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/CBO/" style="font-size: 15px;">CBO</a> <a href="/tags/算法复杂度/" style="font-size: 15px;">算法复杂度</a> <a href="/tags/分布式事务/" style="font-size: 15px;">分布式事务</a> <a href="/tags/ACID/" style="font-size: 15px;">ACID</a> <a href="/tags/CAP/" style="font-size: 15px;">CAP</a> <a href="/tags/Raft/" style="font-size: 15px;">Raft</a> <a href="/tags/分布式一致性/" style="font-size: 15px;">分布式一致性</a> <a href="/tags/数据库/" style="font-size: 15px;">数据库</a> <a href="/tags/AnalyticDB/" style="font-size: 15px;">AnalyticDB</a> <a href="/tags/Intel/" style="font-size: 15px;">Intel</a> <a href="/tags/ARM/" style="font-size: 15px;">ARM</a> <a href="/tags/X86/" style="font-size: 15px;">X86</a> <a href="/tags/硬件/" style="font-size: 15px;">硬件</a> <a href="/tags/RAID/" style="font-size: 15px;">RAID</a> <a href="/tags/服务器/" style="font-size: 15px;">服务器</a> <a href="/tags/窗口函数/" style="font-size: 15px;">窗口函数</a> <a href="/tags/Catalyst/" style="font-size: 15px;">Catalyst</a> <a href="/tags/行列存储/" style="font-size: 15px;">行列存储</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/并发编程/" style="font-size: 15px;">并发编程</a> <a href="/tags/大数据meetup/" style="font-size: 15px;">大数据meetup</a> <a href="/tags/博客/" style="font-size: 15px;">博客</a> <a href="/tags/IT资讯/" style="font-size: 15px;">IT资讯</a> <a href="/tags/故障诊断/" style="font-size: 15px;">故障诊断</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/书籍/" style="font-size: 15px;">书籍</a> <a href="/tags/论文/" style="font-size: 15px;">论文</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/TopK/" style="font-size: 15px;">TopK</a> <a href="/tags/数据结构/" style="font-size: 15px;">数据结构</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/6d27f500.html">Java类加载机制</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/b9b847a8.html">SparkSQL业务分析集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/bfe7107d.html">OLAP引擎-Kylin基本介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/ce4ffa9b.html">Hive性能调优实践</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/19c2ab93.html">Spark性能调优实战</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/c50a937d.html">PMP实践之路</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/7dec2e4.html">Calcite处理和扩展流程解析</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/4c70dee6.html">分布式事务与一致性</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/75c48487.html">2020-DTCC-参会分享</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/8fd5028b.html">SparkSQL窗口函数实操</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://changbo.tech/blog/ec4cdf4c.html" title="行业博客" target="_blank">行业博客</a><ul></ul><a href="https://leetcode-cn.com/" title="leetcode" target="_blank">leetcode</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">Tony's Notes.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>